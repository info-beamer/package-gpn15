#!/usr/bin/python
import os
import sys
import json
import urllib
import traceback
import calendar
from operator import itemgetter
from itertools import cycle
from threading import Thread
from Queue import Queue

from tweepy.streaming import StreamListener
from tweepy import OAuthHandler
from tweepy import Stream

from hosted import CONFIG

CONFIG.restart_on_update()

TMPDIR = os.environ['TMPDIR']

def transform(tweet):
    is_retweet = hasattr(tweet, 'retweeted_status')
    if is_retweet:
        return

    if tweet.user.default_profile:
        return

    if tweet.user.default_profile_image:
        return

    if tweet.text.startswith("@"):
        return

    replacements = []
    for url in tweet.entities.get('urls', ()):
        replacements.append((url['indices'], url['display_url']))
    replacements.sort(reverse=True)

    text = unicode(tweet.text)
    for (start, end), replacement in replacements:
        text = text[:start] + replacement + text[end:]
    text = text.replace("\n", " ")
    text = text.replace("&amp;", "&") # wtf?
    text = text.replace("&lt;", "<") # wtf?
    text = text.replace("&gt;", ">") # wtf?

    for media in tweet.entities.get('media', ()):
        background_image = media['media_url']
        break
    else:
        background_image = None

    return dict(
        screen_name = tweet.user.screen_name,
        profile_image = tweet.user.profile_image_url.replace('_normal', ''),
        text = text,
        background_image = background_image,
        created_at = tweet.created_at,
    )


workqueue= Queue()

class StreamHandler(StreamListener):
    """ A listener handles tweets are the received from the stream.
    This is a basic listener that just prints received tweets to stdout.

    """
    def on_status(self, tweet):
        tweet = transform(tweet)
        if not tweet:
            return

        print >>sys.stderr, tweet
        workqueue.put(tweet)

    def on_error(self, status):
        print status

try:
    tweets = json.load(file("../tweets.json"))
except:
    traceback.print_exc()
    tweets = []

print tweets

class Worker(Thread):
    def run(self):
        next_profile_image = cycle('twitter-profile-%d.jpg' % n for n in range(10)).next
        while 1:
            tweet = workqueue.get()

            # google resizer: http://carlo.zottmann.org/2013/04/14/google-image-resizer/
            data = urllib.urlencode([
                ('container', 'focus'),
                ('url', tweet['profile_image']),
            ])
            image = urllib.urlopen("https://images1-focus-opensocial.googleusercontent.com/gadgets/proxy?%s" % data)

            profile_image = next_profile_image()
            # print "writing profile %s" % profile_image
            with file(os.path.join(TMPDIR, profile_image), "wb") as f:
                f.write(image.read())
            tweet['profile_image'] = profile_image
            try:
                os.unlink(os.path.join("..", profile_image))
            except:
                pass
            os.symlink(os.path.join(TMPDIR, profile_image), os.path.join('..', profile_image))

            tweet['created_at'] = calendar.timegm(tweet['created_at'].utctimetuple())

            tweets.append(tweet)
            tweets.sort(key=itemgetter("created_at"), reverse=True)
            while len(tweets) > 10:
                tweets.pop(10)

            with file("../tweets.json", "wb") as f:
                json.dump(tweets, f)

if __name__ == '__main__':
    auth = OAuthHandler(CONFIG['consumer_key'], CONFIG['consumer_secret'])
    auth.set_access_token(CONFIG['access_token'], CONFIG['access_token_secret'])

    worker = Worker()
    worker.daemon = True
    worker.start()

    stream = Stream(auth, StreamHandler())
    stream.filter(track=CONFIG['search'].split())
